{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T14:02:50.978824Z","iopub.status.busy":"2024-10-01T14:02:50.978462Z","iopub.status.idle":"2024-10-01T14:02:50.984161Z","shell.execute_reply":"2024-10-01T14:02:50.983020Z","shell.execute_reply.started":"2024-10-01T14:02:50.978789Z"},"id":"Cp1jtImov1Tb","trusted":true},"outputs":[],"source":["# https://arxiv.org/pdf/2404.00308"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-01T14:02:51.116861Z","iopub.status.busy":"2024-10-01T14:02:51.116480Z","iopub.status.idle":"2024-10-01T14:02:51.121004Z","shell.execute_reply":"2024-10-01T14:02:51.119951Z","shell.execute_reply.started":"2024-10-01T14:02:51.116824Z"},"id":"qz7a9PqLKi7p","outputId":"bb7df310-971c-4b9a-af04-97b8ef94ca4b","trusted":true},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:00:38.291130Z","iopub.status.busy":"2024-10-02T09:00:38.290122Z","iopub.status.idle":"2024-10-02T09:00:38.304290Z","shell.execute_reply":"2024-10-02T09:00:38.303140Z","shell.execute_reply.started":"2024-10-02T09:00:38.291034Z"},"id":"S6BN6usqqCcQ","trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-02T09:00:51.144349Z","iopub.status.busy":"2024-10-02T09:00:51.144040Z","iopub.status.idle":"2024-10-02T09:04:06.157022Z","shell.execute_reply":"2024-10-02T09:04:06.155930Z","shell.execute_reply.started":"2024-10-02T09:00:51.144318Z"},"id":"06_s_ZOtqCcS","outputId":"6a0b8ea8-af97-4b60-d66c-fbcd6a7aa2ba","scrolled":true,"trusted":true},"outputs":[],"source":["!pip install evaluate\n","!pip install faiss-gpu\n","!python -m pip install scikit-image\n","!pip install pillow\n","!pip install wandb\n","!pip install git+https://github.com/openai/CLIP.git\n","!pip install peft\n","!pip install -q -U bitsandbytes\n","!pip install -q -U git+https://github.com/huggingface/transformers.git\n","!pip install -q -U git+https://github.com/huggingface/peft.git\n","!pip install -q -U git+https://github.com/huggingface/accelerate.git"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:04:06.158875Z","iopub.status.busy":"2024-10-02T09:04:06.158538Z","iopub.status.idle":"2024-10-02T09:04:06.163903Z","shell.execute_reply":"2024-10-02T09:04:06.162995Z","shell.execute_reply.started":"2024-10-02T09:04:06.158841Z"},"id":"TuDrnr1BqCcT","trusted":true},"outputs":[],"source":["import sys\n","sys.path.append('/kaggle/input/yesr/pytorch/default/1')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:04:06.166846Z","iopub.status.busy":"2024-10-02T09:04:06.166548Z","iopub.status.idle":"2024-10-02T09:04:06.180628Z","shell.execute_reply":"2024-10-02T09:04:06.179871Z","shell.execute_reply.started":"2024-10-02T09:04:06.166815Z"},"trusted":true},"outputs":[],"source":["sys.path"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:04:06.181869Z","iopub.status.busy":"2024-10-02T09:04:06.181587Z","iopub.status.idle":"2024-10-02T09:04:09.993910Z","shell.execute_reply":"2024-10-02T09:04:09.992928Z","shell.execute_reply.started":"2024-10-02T09:04:06.181838Z"},"id":"gFgb3NXCqCcU","trusted":true},"outputs":[],"source":["from retriever import GIFFrameRetriever\n","clip_cut = GIFFrameRetriever()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-02T09:04:09.995782Z","iopub.status.busy":"2024-10-02T09:04:09.995253Z","iopub.status.idle":"2024-10-02T09:04:18.422891Z","shell.execute_reply":"2024-10-02T09:04:18.422110Z","shell.execute_reply.started":"2024-10-02T09:04:09.995735Z"},"id":"Flzjpcl7qCcV","outputId":"747e2065-fc96-4198-fc35-2d78ba4df5bd","trusted":true},"outputs":[],"source":["import clip\n","clipm, clipp = clip.load(\"ViT-B/32\", device=\"cuda\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:04:18.425028Z","iopub.status.busy":"2024-10-02T09:04:18.424282Z","iopub.status.idle":"2024-10-02T09:04:32.590470Z","shell.execute_reply":"2024-10-02T09:04:32.589628Z","shell.execute_reply.started":"2024-10-02T09:04:18.424980Z"},"id":"Q2LH-Be9qCcV","trusted":true},"outputs":[],"source":["import math\n","import os\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from transformers import CLIPImageProcessor, GPT2Tokenizer, CLIPProcessor, CLIPModel, GPT2LMHeadModel, Blip2QFormerConfig, Blip2QFormerModel\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn import functional as F\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score, roc_auc_score\n","from nltk.translate.bleu_score import sentence_bleu\n","from evaluate import load\n","import collections\n","from torch.cuda.amp import autocast\n","import numpy as np\n","from nltk.tokenize import TreebankWordTokenizers\n","from peft import LoraConfig, get_peft_model"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:04:32.592116Z","iopub.status.busy":"2024-10-02T09:04:32.591537Z","iopub.status.idle":"2024-10-02T09:04:32.596601Z","shell.execute_reply":"2024-10-02T09:04:32.595685Z","shell.execute_reply.started":"2024-10-02T09:04:32.592053Z"},"id":"cVRK5E-wDVY9","trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:04:32.598323Z","iopub.status.busy":"2024-10-02T09:04:32.597987Z","iopub.status.idle":"2024-10-02T09:04:32.714439Z","shell.execute_reply":"2024-10-02T09:04:32.713642Z","shell.execute_reply.started":"2024-10-02T09:04:32.598291Z"},"id":"TbgDFCLDqCcX","trusted":true},"outputs":[],"source":["class GQADataset(torch.utils.data.Dataset):\n","    def __init__(self, final_data, clip_cut, nf, train_setting = True):\n","        self.questions = final_data['question']\n","        self.image_urls = final_data['url']\n","        self.answers = final_data['answer']\n","        self.clip_cut= clip_cut\n","        self.clipm = clipm\n","        self.clipp = clipp\n","        self.processor = CLIPImageProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n","        self.tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","        self.train_setting = train_setting\n","        self.nf = nf\n","\n","    def __len__(self):\n","        return len(self.image_urls)\n","\n","    def __getitem__(self, idx):\n","\n","        url = self.image_urls[idx]\n","        keyframes = self.clip_cut.retrieve_images_from_gif(url, self.clipm, self.clipp, self.questions[idx], nf)\n","\n","        questions = self.questions[idx]\n","        answers = self.answers[idx]\n","\n","        processed_keyframes = [self.processor(frame, return_tensors='pt')['pixel_values'].squeeze(0) for frame in keyframes]\n","        processed_keyframes = torch.stack(processed_keyframes)\n","\n","        tokens, mask, c_len, t_len = self.pad_sequences(self.questions[idx], self.answers[idx], nf)\n","\n","        tokens = tokens.long()\n","        mask = mask.long()\n","\n","        sample = {'images' : processed_keyframes,\n","                  'tokens': tokens,\n","                  'mask': mask,\n","                  'c_len' : c_len,\n","                  't_len' : t_len,\n","                  'answers' : answers,\n","                  'questions' : questions}\n","\n","        return sample\n","\n","    def pad_sequences(self, questions, answers, nf):\n","        m = [\n","          torch.tensor(self.tokenizer.encode('question: ')),\n","          torch.tensor(self.tokenizer.encode(' context:')),\n","          torch.tensor(self.tokenizer.encode('answer ')),\n","          torch.tensor(self.tokenizer.encode('<|endoftext|>')),\n","      ]\n","        m_mask = [\n","          torch.ones(len(m[0])),\n","          torch.ones(len(m[1])),\n","          torch.ones(len(m[2])),\n","          torch.zeros(len(m[3]))\n","      ]\n","\n","        if self.train_setting:\n","            q = torch.tensor(self.tokenizer.encode(str(questions)))\n","            a = torch.tensor(self.tokenizer.encode(str(answers)))\n","\n","            q, q_mask, leftover_tokens = self.make_padding(32, q, question=True)\n","\n","            c_len =  m[1].size(0)\n","            t_len = m[0].size(0) + nf + q.size(0) + m[1].size(0)\n","\n","            a, a_mask, _ = self.make_padding(32, a, leftover_tokens=leftover_tokens)\n","\n","            if len((a == 0).nonzero()) != 0:\n","                pad_start = (a == 0).nonzero()[0]\n","            else:\n","                pad_start = []\n","\n","            a = torch.cat((a, m[3])) if len(pad_start) == 0 else torch.cat((a[:pad_start], m[3], a[pad_start:]))\n","            q = torch.cat((m[1], torch.ones(nf), m[0],  q, m[2], a))\n","\n","            q_mask = torch.cat((m_mask[1], torch.ones(nf), m_mask[0],  q_mask, m_mask[2], a_mask, m_mask[3]))\n","\n","            return q, q_mask, c_len, t_len\n","        else:\n","            q = torch.tensor(self.tokenizer.encode(str(questions)))\n","            q, q_mask, _ = self.make_padding_test_setting(32, q)\n","\n","            c_len =  m[1].size(0)\n","            t_len = m[0].size(0) + nf + q.size(0) + m[1].size(0)\n","\n","            q = torch.cat((m[1], torch.ones(nf), m[0],  q, m[2]))\n","\n","            q_mask = torch.cat((m_mask[1], torch.ones(nf), m_mask[0],  q_mask, m_mask[2]))\n","            return q, q_mask, c_len, t_len\n","\n","\n","    def make_padding(self, max_len, tokens, question=False, leftover_tokens=0):\n","        padding = max_len - tokens.size(0)\n","        if padding > 0:\n","            if question:\n","                leftover_tokens = padding\n","                mask = torch.ones(tokens.size(0))\n","            else:\n","                tokens = torch.cat((tokens, torch.zeros(padding + leftover_tokens)))\n","                mask = torch.zeros(max_len + leftover_tokens)\n","\n","        elif padding == 0:\n","            if question:\n","                mask = torch.ones(tokens.size(0))\n","            else:\n","                mask = torch.zeros(tokens.size(0) + leftover_tokens)\n","                tokens = torch.cat((tokens, torch.zeros(leftover_tokens)))\n","\n","        elif padding < 0:\n","            if question:\n","                tokens = tokens[:max_len]\n","                mask = torch.ones(max_len)\n","            else:\n","                tokens = torch.cat((tokens[:max_len], torch.zeros(leftover_tokens)))\n","                mask = torch.zeros(max_len + leftover_tokens)\n","\n","        return tokens, mask, leftover_tokens\n","\n","\n","    def make_padding_test_setting(self, max_len, tokens, do_padding=False):\n","        padding = max_len - tokens.size(0)\n","        padding_len = 0\n","        if padding > 0:\n","            if do_padding:\n","                mask = torch.cat((torch.ones(tokens.size(0)), torch.zeros(padding)))\n","                tokens = torch.cat((tokens, torch.zeros(padding)))\n","                padding_len = padding\n","            else:\n","                mask = torch.ones(tokens.size(0))\n","        elif padding == 0:\n","            mask = torch.ones(max_len)\n","        elif padding < 0:\n","            tokens = tokens[:max_len]\n","            mask = torch.ones(max_len)\n","        return tokens, mask, padding_len"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cJFiFL8fqCcY","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:04:32.717856Z","iopub.status.busy":"2024-10-02T09:04:32.717497Z","iopub.status.idle":"2024-10-02T09:04:32.727950Z","shell.execute_reply":"2024-10-02T09:04:32.727120Z","shell.execute_reply.started":"2024-10-02T09:04:32.717822Z"},"id":"Z4t4bczhqCcZ","trusted":true},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, sizes):\n","        super().__init__()\n","        layers = []\n","        for i in range(len(sizes) - 1):\n","            layers.append(nn.Linear(sizes[i], sizes[i + 1]))\n","            if i < len(sizes) - 2:\n","                layers.append(nn.ReLU())\n","        self.model = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return self.model(x)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:04:32.729481Z","iopub.status.busy":"2024-10-02T09:04:32.729093Z","iopub.status.idle":"2024-10-02T09:04:32.738485Z","shell.execute_reply":"2024-10-02T09:04:32.737619Z","shell.execute_reply.started":"2024-10-02T09:04:32.729439Z"},"id":"79rk_OUeJGCJ","trusted":true},"outputs":[],"source":["peft_config = LoraConfig(\n","  task_type=TaskType.CAUSAL_LM, inference_mode=False,\n","  r=8,\n","  lora_alpha=32, lora_dropout=0.1\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-02T09:04:32.740489Z","iopub.status.busy":"2024-10-02T09:04:32.740026Z","iopub.status.idle":"2024-10-02T09:04:32.774653Z","shell.execute_reply":"2024-10-02T09:04:32.773852Z","shell.execute_reply.started":"2024-10-02T09:04:32.740446Z"},"id":"uCmastCjqCca","trusted":true},"outputs":[],"source":["class GQAModel(nn.Module):\n","    def __init__(self, peft_config, nf, num_query_token=3, cross_attention_freq=2):\n","        super().__init__()\n","        self.clip = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n","\n","        for param in self.clip.parameters():\n","            param.requires_grad = False\n","\n","        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","        self.llm = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","        self.peft_config = peft_config\n","        self.llm = get_peft_model(self.llm, self.peft_config)\n","        self.nf=  nf\n","\n","        self.clip_vision_output_dim = self.clip.config.vision_config.hidden_size\n","\n","        self.mapper = MLP(sizes=(self.clip_vision_output_dim, 768, 768))\n","        self.dropout = nn.Dropout(0.1)\n","        self.Qformer, self.query_tokens = self.init_Qformer(nf)\n","        for param in self.Qformer.parameters():\n","            param.requires_grad = False\n","\n","        self.llm_proj = nn.Linear(self.Qformer.config.hidden_size, self.llm.config.hidden_size)\n","        self.image_proj = nn.Linear(512,self.Qformer.config.encoder_hidden_size)\n","\n","    def init_Qformer(self, num_query_token=3):\n","        qformer_config = Blip2QFormerConfig.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n","        qformer_config.query_length = num_query_token\n","\n","        Qformer = Blip2QFormerModel.from_pretrained(\"Salesforce/blip2-opt-2.7b\", config=qformer_config)\n","        query_tokens = nn.Parameter(torch.zeros(1, num_query_token, qformer_config.hidden_size))\n","        query_tokens.data.normal_(mean=0.0, std=qformer_config.initializer_range)\n","\n","        return Qformer, query_tokens\n","\n","    def forward(self, images, tokens, mask, c_len):\n","        batch_size, num_frames, c, h, w = images.size()\n","\n","        images_reshaped = images.view(-1, c, h, w)\n","        image_features = self.clip.get_image_features(images_reshaped)\n","\n","        image_features = self.image_proj(image_features)\n","        image_features = image_features.view(batch_size, num_frames, -1)\n","\n","        image_atts = torch.ones(image_features.size()[:-1], dtype=torch.long).to(images.device)\n","        query_tokens = self.query_tokens.expand(batch_size, -1, -1) \n","        query_output = self.Qformer(\n","            query_embeds=query_tokens,\n","            encoder_hidden_states=image_features,\n","            encoder_attention_mask=image_atts,\n","            return_dict=True,\n","        )\n","\n","        V = self.llm_proj(query_output.last_hidden_state)\n","\n","        sigma = 0.1\n","        rho = 0.5 + sigma * torch.randn(1).item()\n","        rho = torch.clamp(torch.tensor(rho), 0.3, 0.7).item()\n","        dynamic_mask = torch.rand((V.shape[0], V.shape[1], V.shape[2]), device=V.device) > rho\n","\n","        V_masked = V * dynamic_mask.float()\n","        caption_features = self.llm.transformer.wte(tokens)\n","\n","        caption_features_masked = caption_features\n","        caption_features_unmasked = caption_features\n","\n","        for b in range(caption_features.shape[0]):\n","            caption_features_masked[b,c_len[b]:c_len[b]+self.nf,:] = V_masked[b]\n","        for b in range(caption_features.shape[0]):\n","            caption_features_masked[b,c_len[b]:c_len[b]+self.nf,:] = V[b]\n","\n","        llm_output_unmasked = self.llm(inputs_embeds=caption_features_unmasked, attention_mask=mask,output_hidden_states=True)\n","        llm_output_masked = self.llm(inputs_embeds=caption_features_masked, attention_mask=mask, output_hidden_states=True)\n","\n","        masked_out = llm_output_masked.hidden_states[-1]\n","        unmasked_out = llm_output_unmasked.hidden_states[-1]\n","\n","        return llm_output_masked, masked_out, unmasked_out, dynamic_mask\n","\n","    def generate(self, images, tokens, mask, c_len):\n","\n","\n","        batch_size, num_frames, c, h, w = images.size()\n","\n","        images_reshaped = images.view(-1, c, h, w)\n","        image_features = self.clip.get_image_features(images_reshaped)\n","        print(image_features.shape)\n","\n","        image_features = self.image_proj(image_features)\n","        image_features = image_features.view(batch_size, num_frames, -1)\n","\n","        image_atts = torch.ones(image_features.size()[:-1], dtype=torch.long).to(images.device)\n","        query_tokens = self.query_tokens.expand(batch_size, -1, -1)\n","\n","        query_output = self.Qformer(\n","            query_embeds=query_tokens,\n","            encoder_hidden_states=image_features,\n","            encoder_attention_mask=image_atts,\n","            return_dict=True,\n","        )\n","\n","        V = self.llm_proj(query_output.last_hidden_state)\n","\n","        embedding = self.llm.transformer.wte(tokens)\n","\n","        for b in range(embedding.shape[0]):\n","                 embedding[b,c_len[b]:c_len[b]+self.nf,:] = V[b]\n","\n","        return embedding"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:04:32.776028Z","iopub.status.busy":"2024-10-02T09:04:32.775727Z","iopub.status.idle":"2024-10-02T09:04:33.029843Z","shell.execute_reply":"2024-10-02T09:04:33.028827Z","shell.execute_reply.started":"2024-10-02T09:04:32.775997Z"},"id":"GeV250R7qCcb","trusted":true},"outputs":[],"source":["df = pd.read_csv('/kaggle/input/dataset/data.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"execution":{"iopub.execute_input":"2024-10-02T09:04:33.031309Z","iopub.status.busy":"2024-10-02T09:04:33.030978Z","iopub.status.idle":"2024-10-02T09:04:33.049074Z","shell.execute_reply":"2024-10-02T09:04:33.048189Z","shell.execute_reply.started":"2024-10-02T09:04:33.031277Z"},"id":"P673bd8lLJMS","outputId":"0267d106-607f-4384-872e-123f5ed46cc8","trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:04:34.155135Z","iopub.status.busy":"2024-10-02T09:04:34.154748Z","iopub.status.idle":"2024-10-02T09:04:34.173324Z","shell.execute_reply":"2024-10-02T09:04:34.172387Z","shell.execute_reply.started":"2024-10-02T09:04:34.155086Z"},"id":"RFGlZbKUqCcb","trusted":true},"outputs":[],"source":["train_data = df.sample(frac = 0.0068).reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106,"referenced_widgets":["cbe20e5e37e54b56bf9b0786cfb00499","9519333b6c8a4e469445256225dab373","e7eb47a646b048588c8edf5b3cc07a94","e405bbbdc5784d50918356df042d0361","d84097081b57485f96a9a34786dba2cb","d0636d7ef4fb4f378e8d9cac34cf2dd6","9921d81fbb42487eb748dbf6019c89b7","7163b142389b47afbf538540031af2d2","62c345ab609949fcad549e73dffdaee9","c36ec13699cb4fa3a7f6291745cd9a93","256e2418310e48afbd69a3ea37da5ec2"]},"execution":{"iopub.execute_input":"2024-10-01T17:37:50.753189Z","iopub.status.busy":"2024-10-01T17:37:50.752868Z","iopub.status.idle":"2024-10-01T17:37:55.853009Z","shell.execute_reply":"2024-10-01T17:37:55.851990Z","shell.execute_reply.started":"2024-10-01T17:37:50.753157Z"},"id":"GyLat07RqCcb","outputId":"c83f8ba7-536a-4c20-8ac3-fd4f6f114617","scrolled":true,"trusted":true},"outputs":[],"source":["batch_size = 16\n","epochs = 10\n","learning_rate = 1e-3\n","nf=5\n","\n","train_dataset = GQADataset(train_data, clip_cut, nf, train_setting = True)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","model = GQAModel(peft_config, nf).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n","MODEL_PATH = '/kaggle/working//best_model.pth'"]},{"cell_type":"code","execution_count":113,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T17:37:55.855123Z","iopub.status.busy":"2024-10-01T17:37:55.854810Z","iopub.status.idle":"2024-10-01T17:37:55.859594Z","shell.execute_reply":"2024-10-01T17:37:55.858621Z","shell.execute_reply.started":"2024-10-01T17:37:55.855089Z"},"id":"LZOQ7bpJ8Zku","trusted":true},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":114,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T17:37:55.861200Z","iopub.status.busy":"2024-10-01T17:37:55.860896Z","iopub.status.idle":"2024-10-01T17:37:55.871606Z","shell.execute_reply":"2024-10-01T17:37:55.870670Z","shell.execute_reply.started":"2024-10-01T17:37:55.861168Z"},"id":"JGQUVHrjJGCM","trusted":true},"outputs":[],"source":["def calculate_mvm_loss(masked_out , unmasked_out, dynamic_mask, c_len, num_frames):\n","        batch_size = masked_out.shape[0]\n","        mse_loss = 0\n","        total_tokens = 0\n","\n","        for b in range(batch_size):\n","            start_idx = c_len[b]\n","            end_idx = start_idx + num_frames\n","\n","            masked_visual = masked_out[b, start_idx:end_idx]\n","            unmasked_visual = unmasked_out[b, start_idx:end_idx]\n","\n","            mask = dynamic_mask[b]\n","\n","            # Select unmasked tokens\n","            unmasked_indices = ~mask\n","            v_masked = masked_visual[unmasked_indices]\n","            v_unmasked = unmasked_visual[unmasked_indices]\n","\n","            # Compute MSE loss for this batch\n","            mse_loss += F.mse_loss(v_masked, v_unmasked, reduction='sum')\n","            total_tokens += unmasked_indices.sum().item()\n","\n","        # Normalize by (1 - ρ)KT\n","        rho = dynamic_mask.float().mean().item()\n","        mvm_loss = mse_loss / ((1 - rho) * total_tokens)\n","\n","        return mvm_loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import wandb\n","\n","wandb.init(project=\"first run\", config={\n","    \"epochs\": epochs,\n","    \"batch_size\": batch_size,\n","    \"learning_rate\": learning_rate\n","})"]},{"cell_type":"code","execution_count":116,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T17:37:59.648478Z","iopub.status.busy":"2024-10-01T17:37:59.648189Z","iopub.status.idle":"2024-10-01T17:37:59.654707Z","shell.execute_reply":"2024-10-01T17:37:59.653791Z","shell.execute_reply.started":"2024-10-01T17:37:59.648444Z"},"id":"rSFJkva1NkrX","trusted":true},"outputs":[],"source":["# https://wandb.ai/authorize"]},{"cell_type":"code","execution_count":117,"metadata":{"execution":{"iopub.execute_input":"2024-10-01T17:37:59.656107Z","iopub.status.busy":"2024-10-01T17:37:59.655788Z","iopub.status.idle":"2024-10-01T17:37:59.670435Z","shell.execute_reply":"2024-10-01T17:37:59.669583Z","shell.execute_reply.started":"2024-10-01T17:37:59.656057Z"},"id":"2TN7m9ZcqCcc","trusted":true},"outputs":[],"source":["# import shutil\n","\n","def train(model, dataloader, optimizer, scheduler, device):    \n","    for epoch in range(epochs):\n","        model.train()\n","        running_loss = 0.0\n","        total_tokens = 0\n","        for batch in tqdm(train_loader, desc=\"Training\"):\n","            images, tokens, mask, c_len , t_len = batch['images'], batch['tokens'], batch['mask'], batch['c_len'], batch['t_len'],\n","            images = images.to(device)\n","            tokens = tokens.to(device)\n","            mask = mask.to(device)\n","            t_len = t_len.to(device)\n","            c_len = c_len.to(device)\n","\n","            optimizer.zero_grad()\n","            logits, masked_out, unmasked_out, dynamic_mask = model(images, tokens, mask, c_len)\n","            logits = logits.logits\n","\n","            l1 = calculate_mvm_loss(masked_out, unmasked_out, dynamic_mask, c_len, nf)\n","            shift = 0\n","            for b in range(logits.size(0)):\n","                            condensed_tokens = tokens[b,t_len[b] + 1:]\n","                            condensed_logits = logits[b,shift + t_len[b]:-1]\n","                        \n","                            loss += F.cross_entropy(condensed_logits.reshape(-1,logits.shape[-1]), condensed_tokens.flatten(), ignore_index=0)\n","                            total_tokens += (condensed_tokens != 0).sum().item()\n","\n","            loss=loss/logits.size(0)\n","            loss = loss + l1\n","            print(\"batch sum loss : \", loss)\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step(loss)\n","            running_loss += loss.item()\n","\n","        print(f\"Train loss: {running_loss:.4f}\")\n","        avg_loss = running_loss / len(dataloader)\n","        perplexity = math.exp(running_loss/total_tokens)\n","        checkpoint_path = f\"checkpoint_{epoch}.pt\"\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'scheduler_state_dict': scheduler.state_dict(),\n","            'loss': avg_loss,\n","        }, checkpoint_path)\n","        wandb.log({\"avg_loss\": avg_loss, 'avg_perp' : perplexity, \"epoch\": epoch+1})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qT14DUvbqCcc","outputId":"57aa67fc-b32d-4e0b-cd87-210054382f2d","scrolled":true,"trusted":true},"outputs":[],"source":["train(model, train_loader, optimizer, scheduler, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-10-01T17:37:01.555254Z","iopub.status.idle":"2024-10-01T17:37:01.555610Z","shell.execute_reply":"2024-10-01T17:37:01.555432Z","shell.execute_reply.started":"2024-10-01T17:37:01.555414Z"},"trusted":true},"outputs":[],"source":["\n","torch.save(model.state_dict(), MODEL_PATH)\n","print(f\"Model saved to {MODEL_PATH}\")\n","print(\"Training complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HrkR65Xqjzh9"},"outputs":[],"source":["# Eval"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:30:54.825946Z","iopub.status.busy":"2024-10-02T09:30:54.825244Z","iopub.status.idle":"2024-10-02T09:30:54.844335Z","shell.execute_reply":"2024-10-02T09:30:54.843307Z","shell.execute_reply.started":"2024-10-02T09:30:54.825906Z"},"id":"i0DARj0751Gv","trusted":true},"outputs":[],"source":["def treebank_tokenize(s):\n","    return TreebankWordTokenizer().tokenize(s)\n","def generate_beam(\n","    model,\n","    tokenizer,\n","    beam_size= 1,\n","    generated=None,\n","    entry_length=50,\n","    temperature=0.8,\n","    stop_token: str = \"<|endoftext|>\",\n","):\n","    model.eval()\n","    stop_token_index = tokenizer.encode(stop_token)[0]\n","    tokens = None\n","    scores = None\n","    device = next(model.parameters()).device\n","    seq_lengths = torch.ones(beam_size, device=device)\n","    is_stopped = torch.zeros(beam_size, device=device, dtype=torch.bool)\n","    with torch.no_grad():\n","        for i in range(entry_length):\n","            outputs = model.llm(inputs_embeds=generated)\n","            logits = outputs.logits\n","\n","            logits = logits[:, -1, :] / (temperature if temperature > 0 else 1.0)\n","\n","            logits = logits.softmax(-1).log()\n","            # final_logit\n","\n","            if scores is None:\n","                scores, next_tokens = logits.topk(beam_size, -1)\n","                generated = generated.expand(beam_size, *generated.shape[1:])\n","                next_tokens, scores = next_tokens.permute(1, 0), scores.squeeze(0)\n","                if tokens is None:\n","                    tokens = next_tokens\n","                else:\n","                    tokens = tokens.expand(beam_size, *tokens.shape[1:])\n","                    tokens = torch.cat((tokens, next_tokens), dim=1)\n","            else:\n","                logits[is_stopped] = -float(np.inf)\n","                logits[is_stopped, 0] = 0\n","                scores_sum = scores[:, None] + logits\n","                seq_lengths[~is_stopped] += 1\n","                scores_sum_average = scores_sum / seq_lengths[:, None]\n","                scores_sum_average, next_tokens = scores_sum_average.view(-1).topk(\n","                    beam_size, -1\n","                )\n","                next_tokens_source = next_tokens // scores_sum.shape[1]\n","                seq_lengths = seq_lengths[next_tokens_source]\n","                next_tokens = next_tokens % scores_sum.shape[1]\n","                next_tokens = next_tokens.unsqueeze(1)\n","                tokens = tokens[next_tokens_source]\n","                tokens = torch.cat((tokens, next_tokens), dim=1)\n","                generated = generated[next_tokens_source]\n","                scores = scores_sum_average * seq_lengths\n","                is_stopped = is_stopped[next_tokens_source]\n","\n","\n","            next_token_embed = model.llm.transformer.wte(next_tokens.squeeze()).view(generated.shape[0], 1, -1)\n","\n","            generated = torch.cat((generated, next_token_embed), dim=1)\n","            is_stopped = is_stopped + next_tokens.eq(stop_token_index).squeeze()\n","            if is_stopped.all():\n","                break\n","    scores = scores / seq_lengths\n","    output_list = tokens.cpu().numpy()\n","    output_texts = [\n","        tokenizer.decode(output[: int(length)])\n","        for output, length in zip(output_list, seq_lengths)\n","    ]\n","    order = scores.argsort(descending=True)\n","    output_texts = [output_texts[i] for i in order]\n","    return output_texts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nY72XHOWJGCN"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:30:55.269781Z","iopub.status.busy":"2024-10-02T09:30:55.268862Z","iopub.status.idle":"2024-10-02T09:30:55.284272Z","shell.execute_reply":"2024-10-02T09:30:55.283261Z","shell.execute_reply.started":"2024-10-02T09:30:55.269739Z"},"id":"nM8WhPAxxLxR","trusted":true},"outputs":[],"source":["def eval_gpt_open_ended(model, dataloader):\n","    model.eval()\n","    model= model.to(device)\n","    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","    bleu_avg1=0.\n","    f1_avg = 0.\n","    acc = 0.\n","    acc_oe = 0.\n","    acc_yn = 0.\n","    c_oe =1e-9\n","    c_yn =1e-9\n","\n","    for batch in tqdm(dataloader, desc=\"Testing\"):\n","        images, tokens, mask, c_len , t_len = batch['images'], batch['tokens'], batch['mask'], batch['c_len'], batch['t_len']\n","        images = images.to(device)\n","        tokens = tokens.to(device)\n","        mask = mask.to(device)\n","        c_len = c_len.to(device)\n","\n","        with autocast(dtype=torch.float16):\n","            with torch.no_grad():\n","                embed = model.generate(images, tokens, mask, c_len)\n","                print(embed.shape)\n","                out_text = generate_beam(model, model.tokenizer,generated=embed,entry_length=30, temperature=1)[0]\n","\n","        out_text = out_text.split(\"<|endoftext|>\")[0]\n","\n","        print('Question: ', batch['questions'])\n","        print('Answer: ', batch['answers'])\n","        print(\"Generated_Answer: \", out_text)\n","\n","        if out_text.lower()==(batch['answers'][0]).lower():\n","            acc+=1\n","\n","        reference = [str((batch['answers'][0]).lower())]\n","        candidate = [out_text]\n","\n","        bleu_1 = sentence_bleu(reference[0], candidate[0], weights=(1, 0, 0, 0))\n","        f1_avg += compute_f1(tokenizer.encode(reference[0]),tokenizer.encode(candidate[0]))\n","        bleu_avg1+=bleu_1\n","\n","    # print('------------')\n","    print(\"BLEU {}\".format(round(bleu_avg1/len(dataloader),3)))\n","    print(\"F1 {}\".format(round(f1_avg/len(dataloader),3)))\n","    print(\"Accuracy {}\".format(round(acc/len(dataloader),3)))\n","\n","\n","def compute_f1(gold_toks, pred_toks):\n","    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n","    num_same = sum(common.values())\n","    if len(gold_toks) == 0 or len(pred_toks) == 0:\n","        return int(gold_toks == pred_toks)\n","    if num_same == 0:\n","        return 0\n","    precision = 1.0 * num_same / len(pred_toks)\n","    recall = 1.0 * num_same / len(gold_toks)\n","    f1 = (2 * precision * recall) / (precision + recall)\n","    return f1"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:24:10.967139Z","iopub.status.busy":"2024-10-02T09:24:10.966744Z","iopub.status.idle":"2024-10-02T09:24:10.971674Z","shell.execute_reply":"2024-10-02T09:24:10.970497Z","shell.execute_reply.started":"2024-10-02T09:24:10.967102Z"},"trusted":true},"outputs":[],"source":["nf=5"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:29:44.442771Z","iopub.status.busy":"2024-10-02T09:29:44.441747Z","iopub.status.idle":"2024-10-02T09:29:45.779567Z","shell.execute_reply":"2024-10-02T09:29:45.778568Z","shell.execute_reply.started":"2024-10-02T09:29:44.442727Z"},"trusted":true},"outputs":[],"source":["ckpt = torch.load('/kaggle/input/weights/pytorch/default/1/checkpoint_2.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:30:03.160332Z","iopub.status.busy":"2024-10-02T09:30:03.159178Z","iopub.status.idle":"2024-10-02T09:30:03.205851Z","shell.execute_reply":"2024-10-02T09:30:03.204910Z","shell.execute_reply.started":"2024-10-02T09:30:03.160275Z"},"trusted":true},"outputs":[],"source":["model.load_state_dict(ckpt['model_state_dict'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:30:12.057461Z","iopub.status.busy":"2024-10-02T09:30:12.057011Z","iopub.status.idle":"2024-10-02T09:30:12.072998Z","shell.execute_reply":"2024-10-02T09:30:12.072123Z","shell.execute_reply.started":"2024-10-02T09:30:12.057421Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["model.state_dict"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:36:13.654929Z","iopub.status.busy":"2024-10-02T09:36:13.654092Z","iopub.status.idle":"2024-10-02T09:36:13.915876Z","shell.execute_reply":"2024-10-02T09:36:13.914863Z","shell.execute_reply.started":"2024-10-02T09:36:13.654891Z"},"trusted":true},"outputs":[],"source":["test_data = df.sample(frac=0.007).reset_index()\n","test_dataset = GQADataset(test_data,  clip_cut, nf, train_setting = False)\n","test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:36:15.809675Z","iopub.status.busy":"2024-10-02T09:36:15.809279Z","iopub.status.idle":"2024-10-02T09:36:15.829434Z","shell.execute_reply":"2024-10-02T09:36:15.828493Z","shell.execute_reply.started":"2024-10-02T09:36:15.809635Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T09:36:17.139935Z","iopub.status.busy":"2024-10-02T09:36:17.139558Z"},"id":"mN5-gwjHxOzU","scrolled":true,"trusted":true},"outputs":[],"source":["eval_gpt_open_ended(model, test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VgFaGKj3JGCO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0J0NuEe0Kf7g"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5797617,"sourceId":9521938,"sourceType":"datasetVersion"},{"datasetId":5799661,"sourceId":9524537,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelId":126577,"modelInstanceId":102357,"sourceId":121639,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelId":126577,"modelInstanceId":102357,"sourceId":122977,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelId":129055,"modelInstanceId":104850,"sourceId":124577,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelId":129080,"modelInstanceId":104872,"sourceId":124606,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelId":129253,"modelInstanceId":105031,"sourceId":124792,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelId":129705,"modelInstanceId":105462,"sourceId":125313,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30776,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"widgets":{"application/vnd.jupyter.widget-state+json":{"256e2418310e48afbd69a3ea37da5ec2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62c345ab609949fcad549e73dffdaee9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7163b142389b47afbf538540031af2d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9519333b6c8a4e469445256225dab373":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0636d7ef4fb4f378e8d9cac34cf2dd6","placeholder":"​","style":"IPY_MODEL_9921d81fbb42487eb748dbf6019c89b7","value":"Loading checkpoint shards: 100%"}},"9921d81fbb42487eb748dbf6019c89b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c36ec13699cb4fa3a7f6291745cd9a93":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbe20e5e37e54b56bf9b0786cfb00499":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9519333b6c8a4e469445256225dab373","IPY_MODEL_e7eb47a646b048588c8edf5b3cc07a94","IPY_MODEL_e405bbbdc5784d50918356df042d0361"],"layout":"IPY_MODEL_d84097081b57485f96a9a34786dba2cb"}},"d0636d7ef4fb4f378e8d9cac34cf2dd6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d84097081b57485f96a9a34786dba2cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e405bbbdc5784d50918356df042d0361":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c36ec13699cb4fa3a7f6291745cd9a93","placeholder":"​","style":"IPY_MODEL_256e2418310e48afbd69a3ea37da5ec2","value":" 2/2 [00:01&lt;00:00,  1.94it/s]"}},"e7eb47a646b048588c8edf5b3cc07a94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7163b142389b47afbf538540031af2d2","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62c345ab609949fcad549e73dffdaee9","value":2}}}}},"nbformat":4,"nbformat_minor":4}
